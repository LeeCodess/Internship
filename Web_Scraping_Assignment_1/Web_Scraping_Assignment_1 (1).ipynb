{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1 - write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee67934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>, <h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>, <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>, <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>, <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>, <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>, <h2 class=\"mp-h2\" id=\"mp-tfl-h2\"><span id=\"From_today.27s_featured_list\"></span><span class=\"mw-headline\" id=\"From_today's_featured_list\">From today's featured list</span></h2>, <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>, <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>, <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>, <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>, <h2>Navigation menu</h2>, <h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>, <h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>]\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = urlopen(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "soup = BeautifulSoup(url, \"html.parser\")\n",
    "\n",
    "header_tag = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "\n",
    "print(header_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2 - write a python program to display imdb’s top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8e85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def a(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    movie = soup.find_all(\"td\", class_ = \"titleColumn\")\n",
    "    title = []\n",
    "    for i in movie:\n",
    "        i = i.text.replace('\\n','')\n",
    "        i = i.rstrip(i[-6:])\n",
    "        head,sep,tail = i.partition('.')\n",
    "        title.append(tail.strip())\n",
    "    title = title[:100]\n",
    "\n",
    "    b = soup.find_all(\"span\", class_ = \"secondaryInfo\")\n",
    "    year = []\n",
    "    for i in b:\n",
    "        year.append(i.text.replace('(','').replace(')', ''))\n",
    "    year = year[:100]\n",
    "    \n",
    "    c = soup.find_all(\"td\", class_ = \"ratingColumn imdbRating\")\n",
    "    rating = []\n",
    "    for i in c:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    rating = rating[:100]\n",
    "\n",
    "    a = pd.DataFrame({\"Movie Name\" : title, \"Rating\" : rating, \"Year\" : year})\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e4b9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Movie Name Rating  Year\n",
       "0            The Shawshank Redemption    9.2  1994\n",
       "1                       The Godfather    9.2  1972\n",
       "2                     The Dark Knight    9.0  2008\n",
       "3               The Godfather Part II    9.0  1974\n",
       "4                        12 Angry Men    8.9  1957\n",
       "..                                ...    ...   ...\n",
       "95                       Citizen Kane    8.3  1941\n",
       "96  M - Eine Stadt sucht einen Mörder    8.3  1931\n",
       "97                 North by Northwest    8.3  1959\n",
       "98                       Idi i smotri    8.2  1985\n",
       "99                            Vertigo    8.2  1958\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a('https://www.imdb.com/chart/top/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3 - write a python program to display imdb’s top rated 100 indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "114f814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def a(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    movie = soup.find_all(\"td\", class_ = \"titleColumn\")\n",
    "    title = []\n",
    "    for i in movie:\n",
    "        i = i.text.replace('\\n','')\n",
    "        i = i.rstrip(i[-6:])\n",
    "        head,sep,tail = i.partition('.')\n",
    "        title.append(tail.strip())\n",
    "    title = title[:100]\n",
    "\n",
    "    b = soup.find_all(\"span\", class_ = \"secondaryInfo\")\n",
    "    year = []\n",
    "    for i in b:\n",
    "        year.append(i.text.replace('(','').replace(')', ''))\n",
    "    year = year[:100]\n",
    "    \n",
    "    c = soup.find_all(\"td\", class_ = \"ratingColumn imdbRating\")\n",
    "    rating = []\n",
    "    for i in c:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    rating = rating[:100]\n",
    "\n",
    "    a = pd.DataFrame({\"Movie Name\" : title, \"Rating\" : rating, \"Year\" : year})\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdea28b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ustad Hotel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Legend of Bhagat Singh</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Angoor</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movie Name Rating  Year\n",
       "0    Rocketry: The Nambi Effect    8.5  2022\n",
       "1                    Anbe Sivam    8.4  2003\n",
       "2                      Jai Bhim    8.4  2021\n",
       "3                       Golmaal    8.4  1979\n",
       "4                       Nayakan    8.4  1987\n",
       "..                          ...    ...   ...\n",
       "95                  Ustad Hotel    8.0  2012\n",
       "96   The Legend of Bhagat Singh    8.0  2002\n",
       "97                    Virumandi    8.0  2004\n",
       "98  Baahubali 2: The Conclusion    8.0  2017\n",
       "99                       Angoor    8.0  1982\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4 - write s python program to display list of respected former presidents of india (i.e. name , term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df8f0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def President_Ind(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    names = soup.find_all(\"div\", class_ = \"presidentListing\")\n",
    "    Name = []\n",
    "    for i in names:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('(')\n",
    "        Name.append(head.replace('\\n',''))\n",
    "\n",
    "    term = soup.find_all(\"div\", class_ = \"presidentListing\")\n",
    "    Term = []\n",
    "    for i in term:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('Term of Office: ')\n",
    "        i = tail\n",
    "        head,sep,tail = i.partition('\\n')\n",
    "        Term.append(head)\n",
    "        \n",
    "    president = pd.DataFrame({\"Name\" : Name, \"Term of Office\" : Term})\n",
    "    return(president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4bd0ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "President_Ind(\"https://presidentofindia.nic.in/former-presidents.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965282f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5 - write a python program to scrape cricket rankings from icc-cricket.com\n",
    "# question 5a - top 10 odi teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aec8bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    team = soup.find_all('span', class_ = 'u-hide-phablet')\n",
    "    Team = []\n",
    "    for i in team:\n",
    "        i = i.get_text()\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    Top_team_r = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(' ', '')\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "    Rating = [Top_team_r]\n",
    "    \n",
    "    for i in rating:\n",
    "        i = i.get_text()\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    match_point = soup.find_all('td', class_ = 'table-body__cell u-center-text')\n",
    "    Match_Point = []\n",
    "    for i in match_point:\n",
    "        i = i.get_text()\n",
    "        Match_Point.append(i)\n",
    "\n",
    "    Top_team_m = soup.find('td', class_ = 'rankings-block__banner--matches').text\n",
    "    Top_team_p = soup.find('td', class_ = 'rankings-block__banner--points').text\n",
    "    Match = [Top_team_m] \n",
    "    Point = [Top_team_p]\n",
    "    i=0  \n",
    "    j=1\n",
    "    \n",
    "    while i<17:\n",
    "        Match.append(Match_Point[i])\n",
    "        Point.append(Match_Point[j])\n",
    "        i = i+2 \n",
    "        j= j+2\n",
    "        \n",
    "    top_odi = pd.DataFrame({\"Team Name\" : Team, \"Rating\" : Rating, \"Matches\" : Match, \"Point\" : Point})\n",
    "    return(top_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "426cfcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>119</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>114</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>111</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>107</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>106</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Rating Matches  Point\n",
       "0       England    119      27  3,226\n",
       "1   New Zealand    114      22  2,508\n",
       "2         India    111      31  3,447\n",
       "3      Pakistan    107      22  2,354\n",
       "4     Australia    106      29  3,071\n",
       "5  South Africa    101      21  2,111\n",
       "6    Bangladesh     92      30  2,753\n",
       "7     Sri Lanka     92      29  2,658\n",
       "8   West Indies     71      41  2,902\n",
       "9   Afghanistan     69      18  1,238"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ed3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5b - top 10 odi batsmen along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84902889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','').split(' ')[0]\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "984b74d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Team Rating\n",
       "0             Babar Azam  PAK    890\n",
       "1  Rassie van der Dussen   SA    789\n",
       "2        Quinton de Kock   SA    784\n",
       "3            Imam-ul-Haq  PAK    779\n",
       "4            Virat Kohli  IND    744\n",
       "5           Rohit Sharma  IND    740\n",
       "6         Jonny Bairstow  ENG    732\n",
       "7           David Warner  AUS    725\n",
       "8            Ross Taylor   NZ    701\n",
       "9            Steve Smith  AUS    697"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5c - top 10 odi bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4f0802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30fdbfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                    Team Rating\n",
       "0       Trent Boult  NZ                        775\n",
       "1    Josh Hazlewood                     AUS    718\n",
       "2  Mujeeb Ur Rahman                     AFG    676\n",
       "3    Jasprit Bumrah                     IND    662\n",
       "4    Shaheen Afridi                     PAK    661\n",
       "5     Mohammad Nabi                     AFG    657\n",
       "6      Mehedi Hasan                     BAN    655\n",
       "7        Matt Henry                      NZ    654\n",
       "8    Mitchell Starc                     AUS    653\n",
       "9       Rashid Khan                     AFG    651"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6 - write a python program to scrape cricket rankings from icc-cricket.com\n",
    "# question 6a - top 10 odi teams in women’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1479bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    team = soup.find_all('span', class_ = 'u-hide-phablet')\n",
    "    Team = []\n",
    "    for i in team:\n",
    "        i = i.get_text()\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "\n",
    "    Top_team_r = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(' ', '')\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "    \n",
    "    Rating = [Top_team_r]\n",
    "    for i in rating:\n",
    "        i = i.get_text()\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    match_point = soup.find_all('td', class_ = 'table-body__cell u-center-text')\n",
    "    \n",
    "    Match_Point = []\n",
    "    for i in match_point:\n",
    "        i = i.get_text()\n",
    "        Match_Point.append(i)\n",
    "\n",
    "    Top_team_a = soup.find('td', class_ = 'rankings-block__banner--matches').text\n",
    "    Top_team_b = soup.find('td', class_ = 'rankings-block__banner--points').text\n",
    "    \n",
    "    Match = [Top_team_a] \n",
    "    Point = [Top_team_b]\n",
    "    i=0  \n",
    "    j=1\n",
    "    while i<17:\n",
    "        Match.append(Match_Point[i])\n",
    "        Point.append(Match_Point[j])\n",
    "        i = i+2 \n",
    "        j= j+2\n",
    "        \n",
    "    Top_odi = pd.DataFrame({\"Team Name\" : Team, \"Rating\" : Rating, \"Matches\" : Match, \"Point\" : Point})\n",
    "    return(Top_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7044d080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>167</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>4,097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>103</td>\n",
       "      <td>33</td>\n",
       "      <td>3,392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>99</td>\n",
       "      <td>32</td>\n",
       "      <td>3,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>91</td>\n",
       "      <td>31</td>\n",
       "      <td>2,815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Rating Matches  Point\n",
       "0     Australia    167      29  4,837\n",
       "1       England    121      34  4,097\n",
       "2  South Africa    119      35  4,157\n",
       "3         India    103      33  3,392\n",
       "4   New Zealand     99      32  3,161\n",
       "5   West Indies     91      31  2,815\n",
       "6    Bangladesh     78      12    930\n",
       "7      Pakistan     65      30  1,962\n",
       "8       Ireland     47      11    516\n",
       "9     Sri Lanka     45      11    495"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86531754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6b - top 10 women’s odi batting players along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e525509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f6324a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                     Team Rating\n",
       "0         Alyssa Healy  AUS                        785\n",
       "1          Beth Mooney                      AUS    749\n",
       "2       Natalie Sciver                      ENG    740\n",
       "3      Laura Wolvaardt                       SA    732\n",
       "4          Meg Lanning                      AUS    710\n",
       "5       Rachael Haynes                      AUS    701\n",
       "6      Smriti Mandhana                      IND    698\n",
       "7    Amy Satterthwaite                       NZ    681\n",
       "8     Harmanpreet Kaur                      IND    662\n",
       "9  Chamari Athapaththu                       SL    655"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6c - top 10 women’s odi all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d0f232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77c823af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                     Team Rating\n",
       "0    Sophie Ecclestone  ENG                        748\n",
       "1        Jess Jonassen                      AUS    725\n",
       "2         Megan Schutt                      AUS    722\n",
       "3       Shabnim Ismail                       SA    722\n",
       "4       Jhulan Goswami                      IND    689\n",
       "5       Ayabonga Khaka                       SA    634\n",
       "6  Rajeshwari Gayakwad                      IND    625\n",
       "7      Hayley Matthews                       WI    612\n",
       "8       Marizanne Kapp                       SA    598\n",
       "9           Kate Cross                      ENG    597"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac09878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7 - write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1d683f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def news_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    title = soup.find_all('a', class_ ='LatestNews-headline')\n",
    "    Title = []\n",
    "    for i in title:\n",
    "        Title.append(i.text) \n",
    "\n",
    "    time = soup.find_all('time', class_ ='LatestNews-timestamp')\n",
    "    Time = []\n",
    "    for i in time:\n",
    "        Time.append(i.text) \n",
    "\n",
    "    link = soup.find_all('div', class_='LatestNews-headlineWrapper')\n",
    "    Link = []\n",
    "    for i in link:\n",
    "        head, sep, tail = str(i).partition('\" title=')\n",
    "        head, sep, tail = head.partition('a class=\"LatestNews-headline\" href=\"')\n",
    "        Link.append(tail)\n",
    "\n",
    "    DataFrame = pd.DataFrame({'News':Title,'Time':Time,'Link':Link})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6384f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldman says buy these kinds of stocks as firm...</td>\n",
       "      <td>26 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/goldman-says-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Costco isn't raising membership fees after ear...</td>\n",
       "      <td>59 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/costco-maintai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass protests in Iran, sparked by woman's deat...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/mass-protests-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One thing this millennial business owner says ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/millennial-bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JetBlue ground operations workers seek union v...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/jetblue-fleet-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Buy these 'free cash flow favorites' as the S&amp;...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/buy-these-free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google CEO Pichai tells employees not to 'equa...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/google-ceo-pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What Cramer is watching — 2-year yield unstopp...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/what-cramer-is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Markets don't like U.K. stimulus plan because ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/-financial-mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here are Friday's biggest analyst calls: Apple...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/here-are-frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inflation Reduction Act's expanded biofuel inc...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/inflation-redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Getting married? How to know when to combine y...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/how-to-know-wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stocks making the biggest moves premarket: Fed...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wedbush upgrades fuboTV to outperform citing '...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/wedbush-upgrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Finding yield in health care stocks during the...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/finding-yield-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>British pound plunges, bonds sink after govern...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/british-pound-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Goldman cuts S&amp;P target to 3,600, sees it fall...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/goldman-cuts-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BMO upgrades Domino's Pizza, predicts 35% rebo...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/bmo-upgrades-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UK government dishes out tax cuts as country b...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/uk-government-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Referendums begin in Ukraine's occupied region...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10-year Treasury yield falls as markets digest...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/10-year-treasu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Putin's nuclear threats raise the risk of an u...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Steve Hanke says the chance of a U.S. recessio...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/there-is-an-80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>European stocks slide 2.8% after weak euro zon...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/european-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Electric vehicle sales set to hit an all-time ...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/electric-vehic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HSBC warns investors to avoid European stocks</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/hsbc-warns-inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>U.S. rates may be rising, but Asia won't see a...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/analysts-discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fund manager names 2 UK stocks he says look ve...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/fund-manager-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Credit Suisse says buy stocks with this charac...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/credit-suisse-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 News          Time  \\\n",
       "0   Goldman says buy these kinds of stocks as firm...    26 Min Ago   \n",
       "1   Costco isn't raising membership fees after ear...    59 Min Ago   \n",
       "2   Mass protests in Iran, sparked by woman's deat...    1 Hour Ago   \n",
       "3   One thing this millennial business owner says ...    1 Hour Ago   \n",
       "4   JetBlue ground operations workers seek union v...    1 Hour Ago   \n",
       "5   Buy these 'free cash flow favorites' as the S&...   2 Hours Ago   \n",
       "6   Google CEO Pichai tells employees not to 'equa...   2 Hours Ago   \n",
       "7   What Cramer is watching — 2-year yield unstopp...   2 Hours Ago   \n",
       "8   Markets don't like U.K. stimulus plan because ...   3 Hours Ago   \n",
       "9   Here are Friday's biggest analyst calls: Apple...   3 Hours Ago   \n",
       "10  Inflation Reduction Act's expanded biofuel inc...   3 Hours Ago   \n",
       "11  Getting married? How to know when to combine y...   3 Hours Ago   \n",
       "12  Stocks making the biggest moves premarket: Fed...   4 Hours Ago   \n",
       "13  Wedbush upgrades fuboTV to outperform citing '...   4 Hours Ago   \n",
       "14  5 things to know before the stock market opens...   4 Hours Ago   \n",
       "15  Finding yield in health care stocks during the...   5 Hours Ago   \n",
       "16  British pound plunges, bonds sink after govern...   5 Hours Ago   \n",
       "17  Goldman cuts S&P target to 3,600, sees it fall...   5 Hours Ago   \n",
       "18  BMO upgrades Domino's Pizza, predicts 35% rebo...   5 Hours Ago   \n",
       "19  UK government dishes out tax cuts as country b...   6 Hours Ago   \n",
       "20  Referendums begin in Ukraine's occupied region...   7 Hours Ago   \n",
       "21  10-year Treasury yield falls as markets digest...   7 Hours Ago   \n",
       "22  Putin's nuclear threats raise the risk of an u...   8 Hours Ago   \n",
       "23  Steve Hanke says the chance of a U.S. recessio...   8 Hours Ago   \n",
       "24  European stocks slide 2.8% after weak euro zon...   9 Hours Ago   \n",
       "25  Electric vehicle sales set to hit an all-time ...  10 Hours Ago   \n",
       "26      HSBC warns investors to avoid European stocks  10 Hours Ago   \n",
       "27  U.S. rates may be rising, but Asia won't see a...  10 Hours Ago   \n",
       "28  Fund manager names 2 UK stocks he says look ve...  11 Hours Ago   \n",
       "29  Credit Suisse says buy stocks with this charac...  12 Hours Ago   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/09/23/goldman-says-b...  \n",
       "1   https://www.cnbc.com/2022/09/23/costco-maintai...  \n",
       "2   https://www.cnbc.com/2022/09/23/mass-protests-...  \n",
       "3   https://www.cnbc.com/2022/09/23/millennial-bus...  \n",
       "4   https://www.cnbc.com/2022/09/23/jetblue-fleet-...  \n",
       "5   https://www.cnbc.com/2022/09/23/buy-these-free...  \n",
       "6   https://www.cnbc.com/2022/09/23/google-ceo-pic...  \n",
       "7   https://www.cnbc.com/2022/09/23/what-cramer-is...  \n",
       "8   https://www.cnbc.com/2022/09/23/-financial-mar...  \n",
       "9   https://www.cnbc.com/2022/09/23/here-are-frida...  \n",
       "10  https://www.cnbc.com/2022/09/23/inflation-redu...  \n",
       "11  https://www.cnbc.com/2022/09/23/how-to-know-wh...  \n",
       "12  https://www.cnbc.com/2022/09/23/stocks-making-...  \n",
       "13  https://www.cnbc.com/2022/09/23/wedbush-upgrad...  \n",
       "14  https://www.cnbc.com/2022/09/23/5-things-to-kn...  \n",
       "15  https://www.cnbc.com/2022/09/23/finding-yield-...  \n",
       "16  https://www.cnbc.com/2022/09/23/british-pound-...  \n",
       "17  https://www.cnbc.com/2022/09/23/goldman-cuts-y...  \n",
       "18  https://www.cnbc.com/2022/09/23/bmo-upgrades-d...  \n",
       "19  https://www.cnbc.com/2022/09/23/uk-government-...  \n",
       "20  https://www.cnbc.com/2022/09/23/russia-ukraine...  \n",
       "21  https://www.cnbc.com/2022/09/23/10-year-treasu...  \n",
       "22  https://www.cnbc.com/2022/09/23/russia-ukraine...  \n",
       "23  https://www.cnbc.com/2022/09/23/there-is-an-80...  \n",
       "24  https://www.cnbc.com/2022/09/23/european-stock...  \n",
       "25  https://www.cnbc.com/2022/09/23/electric-vehic...  \n",
       "26  https://www.cnbc.com/2022/09/23/hsbc-warns-inv...  \n",
       "27  https://www.cnbc.com/2022/09/23/analysts-discu...  \n",
       "28  https://www.cnbc.com/2022/09/23/fund-manager-n...  \n",
       "29  https://www.cnbc.com/2022/09/23/credit-suisse-...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_content('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 8 - write a python program to scrape the details of most downloaded articles from ai in last 90 days\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5cdee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def journal(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    title = soup.find_all('h2', class_ ='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR')\n",
    "    Title = []\n",
    "    for i in title:\n",
    "        Title.append(i.text) \n",
    "\n",
    "    author = soup.find_all('span', class_ ='sc-1w3fpd7-0 pgLAT')\n",
    "    Author = []\n",
    "    for i in author:\n",
    "        Author.append(i.text) \n",
    "\n",
    "    date = soup.find_all('span', class_ ='sc-1thf9ly-2 bKddwo')\n",
    "    Date = []\n",
    "    for i in date:\n",
    "        Date.append(i.text) \n",
    "\n",
    "    link = soup.find_all('a', class_ ='sc-5smygv-0 nrDZj')\n",
    "    Link = []\n",
    "    for i in link:\n",
    "        Link.append(i['href'])\n",
    "        \n",
    "    DataFrame = pd.DataFrame({'Paper':Title,'Author':Author,'Publication Date':Date,'Link':Link})\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a0d4198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Paper  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author Publication Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...     October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more     October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni      October 2015   \n",
       "3                                 Boden, Margaret A.       August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more        June 2017   \n",
       "5                                        Miller, Tim     February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more       April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...    February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...      August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more       March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...    February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.      October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more      August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more       April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat     December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant       August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders    September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...        June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.     December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge    September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...         May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...     January 2014   \n",
       "22                      Kohavi, Ron, John, George H.     December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...     October 2021   \n",
       "24                                   Ying, Mingsheng     February 2010   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073879dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 9 - write a python program to scrape mentioned details from dineout.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a521f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def hotel(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    Hotel_name = []\n",
    "    Location = []\n",
    "    for i in soup.find_all('div', class_ = 'restnt-info cursor'):\n",
    "        Hotel_name.append(i.a.text)\n",
    "        Location.append(i.div.text)\n",
    "\n",
    "    Cuisine = []\n",
    "    for i in soup.find_all('span', class_ = 'double-line-ellipsis'):\n",
    "        head, sep, tail = i.text.partition('|')\n",
    "        Cuisine.append(tail)\n",
    "\n",
    "    url = []\n",
    "    for i in soup.find_all('img', class_ = 'no-img'):\n",
    "        url.append(i['data-src'])\n",
    "\n",
    "    Rating = []\n",
    "    for i in soup.find_all('div', class_ = 'restnt-rating rating-4'):\n",
    "        Rating.append(i.text)\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Hotel':Hotel_name, 'Cuisine':Cuisine, 'Location':Location, 'Rating':Rating, 'URL':url})\n",
    "    return(DataFrame)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18a5b762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>Continental, Asian, Italian, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Local</td>\n",
       "      <td>North Indian, Asian, Continental</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Openhouse Cafe</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Station Bar</td>\n",
       "      <td>Italian, Chinese, North Indian, Fast Food</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ministry Of Beer</td>\n",
       "      <td>North Indian, Continental, American, Asian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QBA</td>\n",
       "      <td>North Indian, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Junkyard Cafe</td>\n",
       "      <td>North Indian, Continental, Chinese, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The G.T. ROAD</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Berco's</td>\n",
       "      <td>Chinese, Thai</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Connaught Clubhouse Microbrewery</td>\n",
       "      <td>North Indian, Continental, Asian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unplugged Courtyard</td>\n",
       "      <td>North Indian, Italian, Chinese, Turkish, Cont...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chido</td>\n",
       "      <td>North Indian, Italian, Continental, Asian, Fi...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Farzi Cafe</td>\n",
       "      <td>Modern Indian, Continental, Finger Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ardor 2.1 Restaurant and Lounge</td>\n",
       "      <td>North Indian, Chinese, Italian, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>My Bar Headquarters</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sandoz</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Luggage Room By Sandoz</td>\n",
       "      <td>Chinese, Italian, North Indian, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Out Of The Box Courtyard</td>\n",
       "      <td>North Indian, Mediterranean, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chili's American Grill and Bar</td>\n",
       "      <td>Mexican, American, Tex Mex</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dhaba Estd 1986 Delhi</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hotel  \\\n",
       "0                            Tamasha   \n",
       "1                              Local   \n",
       "2                     Openhouse Cafe   \n",
       "3                        Station Bar   \n",
       "4                   Ministry Of Beer   \n",
       "5                                QBA   \n",
       "6                  The Junkyard Cafe   \n",
       "7                      The G.T. ROAD   \n",
       "8                            Berco's   \n",
       "9   Connaught Clubhouse Microbrewery   \n",
       "10               Unplugged Courtyard   \n",
       "11                             Chido   \n",
       "12                        Farzi Cafe   \n",
       "13   Ardor 2.1 Restaurant and Lounge   \n",
       "14               My Bar Headquarters   \n",
       "15                       38 Barracks   \n",
       "16                            Sandoz   \n",
       "17        The Luggage Room By Sandoz   \n",
       "18          Out Of The Box Courtyard   \n",
       "19    Chili's American Grill and Bar   \n",
       "20             Dhaba Estd 1986 Delhi   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0           Continental, Asian, Italian, North Indian   \n",
       "1                    North Indian, Asian, Continental   \n",
       "2                        North Indian, Asian, Italian   \n",
       "3           Italian, Chinese, North Indian, Fast Food   \n",
       "4          North Indian, Continental, American, Asian   \n",
       "5                  North Indian, Continental, Italian   \n",
       "6       North Indian, Continental, Chinese, Fast Food   \n",
       "7                                        North Indian   \n",
       "8                                       Chinese, Thai   \n",
       "9           North Indian, Continental, Asian, Chinese   \n",
       "10   North Indian, Italian, Chinese, Turkish, Cont...   \n",
       "11   North Indian, Italian, Continental, Asian, Fi...   \n",
       "12            Modern Indian, Continental, Finger Food   \n",
       "13        North Indian, Chinese, Italian, Continental   \n",
       "14                              North Indian, Chinese   \n",
       "15                 North Indian, Chinese, Continental   \n",
       "16                 North Indian, Chinese, Continental   \n",
       "17        Chinese, Italian, North Indian, Continental   \n",
       "18      North Indian, Mediterranean, Chinese, Italian   \n",
       "19                         Mexican, American, Tex Mex   \n",
       "20                              North Indian, Mughlai   \n",
       "\n",
       "                                        Location Rating  \\\n",
       "0                 Connaught Place, Central Delhi    4.2   \n",
       "1   Scindia House,Connaught Place, Central Delhi      4   \n",
       "2                 Connaught Place, Central Delhi    4.1   \n",
       "3         F-Block,Connaught Place, Central Delhi    4.1   \n",
       "4         M-Block,Connaught Place, Central Delhi      4   \n",
       "5                 Connaught Place, Central Delhi    4.3   \n",
       "6                 Connaught Place, Central Delhi    4.1   \n",
       "7         M-Block,Connaught Place, Central Delhi    4.3   \n",
       "8                 Connaught Place, Central Delhi    4.3   \n",
       "9                 Connaught Place, Central Delhi    4.2   \n",
       "10                Connaught Place, Central Delhi      4   \n",
       "11                Connaught Place, Central Delhi    4.2   \n",
       "12                Connaught Place, Central Delhi    4.1   \n",
       "13                Connaught Place, Central Delhi    3.8   \n",
       "14                Connaught Place, Central Delhi      4   \n",
       "15        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "16                Connaught Place, Central Delhi      4   \n",
       "17        M-Block,Connaught Place, Central Delhi    3.9   \n",
       "18                Connaught Place, Central Delhi    4.1   \n",
       "19        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "20                Connaught Place, Central Delhi      4   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel('https://www.dineout.co.in/delhi-restaurants/welcome-back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b83111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 10 - write a python program to scrape the details of top publications from google scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "addf6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def paper(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    rank = soup.find_all('td', class_ ='gsc_mvt_p')\n",
    "    Rank = []\n",
    "    for i in rank:\n",
    "        Rank.append(i.text) \n",
    "\n",
    "    publication = soup.find_all('td', class_ ='gsc_mvt_t')\n",
    "    Publication = []\n",
    "    for i in publication:\n",
    "        Publication.append(i.text) \n",
    "\n",
    "    h5_index = soup.find_all('a', class_ ='gs_ibl gsc_mp_anchor')\n",
    "    H5_index = []\n",
    "    for i in h5_index:\n",
    "        H5_index.append(i.text) \n",
    "\n",
    "    h5_median = soup.find_all('span', class_ ='gs_ibl gsc_mp_anchor')\n",
    "    H5_median = []\n",
    "    for i in h5_median:\n",
    "        H5_median.append(i.text)\n",
    "                                                        \n",
    "    DataFrame = pd.DataFrame({'Rank':Rank,'Publication':Publication,'h5_index':H5_index,'h5_median':H5_median})\n",
    "    return(DataFrame)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56e9a4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5_index</th>\n",
       "      <th>h5_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5_index h5_median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
